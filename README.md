# Data Engineering ZoomCamp - Module 5 - Batch

This is the fifth issue of the Data Engineering Zoomcamp repositories.

In this ocasion we had to use Apache Spark to process a dataset in batch
in a local setup.

All the questions have been solved by using the SQL version of the query,
although they could had been solved also by using the Python Spark objects
directly.

Using SQL allows for easy migration of those queries to a data warehouse or
some other DDBB engine, while the Python code can be better for some
queries that are not easy to express in SQL.

The first query (number 2), starts from the files in disk (thay you should
have previously downloaded) and write the dataset back to disk in parquet
format.
The subsequent queries start from the parquet files generated by the first
question or from the raw data in case the files do not exist.
That allows you to run any of the queries standalone, without any dependency
on any other execution or query.